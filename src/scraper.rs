// Scraper does the following:
// - Takes spider start requests and passes them to the engine
// - Enqueues result from engine and passes back to the crawler
// - Handles spider output and error
// - Handles items generated by the spider
// - [Optional] Plugs in item processing middleware.
use crate::request::{Request, CallbackReturn};
use crate::response::Response;
use crate::spider::{Spider, SpiderOutput};
use crate::downloader::DownloadResult;

use tokio::sync::mpsc::{self, Receiver, Sender};


pub struct Scraper {
    result_tx: Sender<DownloadResult>,
    output_tx: Sender<CallbackReturn>,
    spider: Box<dyn Spider>,
}

impl Scraper {
    pub fn new(buffer: usize, spider: Box<dyn Spider>) -> (Self, Receiver<DownloadResult>, Receiver<CallbackReturn>) {
        let (result_tx, result_rx) = mpsc::channel(buffer);
        let (output_tx, output_rx) = mpsc::channel(buffer);
        (
            Self {
                result_tx,
                output_tx,
                spider,
            },
            result_rx,
            output_rx,
        )
    }

    pub async fn enqueue_response(
        &self,
        result: DownloadResult,
    ) -> Result<(), tokio::sync::mpsc::error::SendError<DownloadResult>> {
        self.result_tx.send(result).await
    }

    pub fn generate_start_requests(&self) -> impl Iterator<Item = Request> + '_ {
        self.spider.start().map(|req| {
            req.validate();
            req.as_start()
        })
    }

    pub async fn process_response(&self, result_rx: &mut Receiver<DownloadResult>) {
        if let Some(download_result) = result_rx.recv().await {
            let response = Response::from(download_result);
            let output = (response.request.callback)(response);
            self.enqueue_spider_output(output).await;
        }
    }

    async fn enqueue_spider_output(&self, output: CallbackReturn) {
        let _ = self.output_tx.send(output).await;
    }

    pub async fn process_spider_output(&self, output_rx: &mut Receiver<CallbackReturn>) {
        if let Some(spider_output_iter) = output_rx.recv().await {
            for spider_output in spider_output_iter {
                match &spider_output {
                    SpiderOutput::Item(item) => {
                        // TODO:: Implement ItemManager
                    }
                    SpiderOutput::Request(request) => {
                        // TODO:: Implement Spider Request Output handler
                    }
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use reqwest::Response as ReqwestResponse;
    use std::sync::atomic::{AtomicBool, Ordering};


    static FLAG: AtomicBool = AtomicBool::new(false);

    // A simple function pointer callback that flips the flag
    fn dummy_callback(_: Response) -> CallbackReturn {
        FLAG.store(true, Ordering::SeqCst);
        Box::new(std::iter::empty())
    }

    struct TestSpider;

    impl Spider for TestSpider {
        fn start(&self) -> Box<dyn Iterator<Item = Request> + Send> {
            let url = "http://example.com";
            let request = Request::get(url);
            Box::new(vec![request].into_iter())
        }
    }

    struct BadSpider;

    impl Spider for BadSpider {
        fn start(&self) -> Box<dyn Iterator<Item = Request> + Send> {
            Box::new(vec![Request::default()].into_iter())
        }
    }


    #[tokio::test]
    async fn test_generate_start_requests_marks_requests_as_start() {
        let (scraper, _result_rx, _output_rx) = Scraper::new(10, Box::new(TestSpider));
        let mut requests = scraper.generate_start_requests();

        let req = requests.next().expect("Expected at least one request");
        assert!(
            req.is_start_request(),
            "Request was not marked as start request"
        );
    }

    #[test]
    #[should_panic(expected = "ValidationError: Callback cannot be empty")]
    fn test_generate_start_requests_panics_on_empty_callback() {
        let (scraper, _result_rx, _output_rx) = Scraper::new(10, Box::new(BadSpider));
        let mut requests = scraper.generate_start_requests();
        let _ = requests.next();
    }

    #[tokio::test]
    async fn test_scraper_process_response_callback() {
        let (scraper, mut result_rx, _output_rx) = Scraper::new(10, Box::new(TestSpider));

        let dummy_req = Request::get("http://example.com").with_callback(dummy_callback);
        let dummy_res = http::Response::builder()
            .status(200)
            .body(Vec::new())
            .unwrap();
        let reqwest_res = ReqwestResponse::from(dummy_res);

        let download_result = DownloadResult {
            request: dummy_req,
            response: reqwest_res,
        };
        let _ = scraper.enqueue_response(download_result).await;
        scraper.process_response(&mut result_rx).await;
        assert!(FLAG.load(Ordering::SeqCst), "Callback was not triggered");
    }
}
