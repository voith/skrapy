// Scraper does the following:
// - Takes spider start requests and passes them to the engine
// - Enqueues result from engine and passes back to the crawler
// - Handles spider output and error
// - Handles items generated by the spider
// - [Optional] Plugs in item processing middleware. 
use tokio::sync::mpsc::{self, Sender, Receiver};
use crate::response::Response;
use crate::spider::Spider;

struct Scraper {
    response_tx: Sender<Response>,
    response_rx: Receiver<Response>,
    spider: Box<dyn Spider>,
}

impl Scraper {
    pub fn new(buffer: usize, spider: Box<dyn Spider>) -> Self {
        let (response_tx, response_rx) = mpsc::channel(buffer);
        Self {
            response_tx,
            response_rx,
            spider,
        }
    }

    pub async fn enqueue_response(&self, response: Response) -> Result<(), tokio::sync::mpsc::error::SendError<Response>> {
        self.response_tx.send(response).await
    }
}
